{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from template import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26894142, 0.73105858],\n",
       "       [0.31002552, 0.68997448]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    # Berechnung des Softmax für jede Zeile der Eingabematrix\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    softmax_x = exp_x / exp_x.sum(axis=1, keepdims=True)\n",
    "    return softmax_x\n",
    "\n",
    "softmax(np.array([[-1., 0.], [0.2, 1.]])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.37285946 0.73278279]\n",
      " [0.36712163 0.72522747]\n",
      " [0.36637032 0.72842298]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(4321)\n",
    "q = np.random.rand(3,2)\n",
    "k = np.random.rand(3,2)\n",
    "v = np.random.rand(3,2)\n",
    "x = attention(q, k, v)\n",
    "print(x)\n",
    "\n",
    "#      [[0.37285946 0.73278279]\n",
    "#      [0.36712163 0.72522747]\n",
    "#      [0.36637032 0.72842298]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def masked_attention(Q, K, V, mask):\n",
    "    M = ((Q@np.transpose(K)) / np.sqrt(K.shape[1]) + mask) ## d_k = dim von K\n",
    "    a = softmax(M) @ V\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.37646796 0.24378126]\n",
      " [0.48299578 0.28439644]\n",
      " [0.46590072 0.41837738]\n",
      " [0.52991302 0.51314059]\n",
      " [0.49214214 0.55574465]\n",
      " [0.39568092 0.59955323]\n",
      " [0.38462954 0.61108759]\n",
      " [0.37248739 0.5645996 ]\n",
      " [0.35915127 0.57331419]\n",
      " [0.41913397 0.51187079]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(4321)\n",
    "nf = 10\n",
    "q = np.random.rand(nf,2)\n",
    "k = np.random.rand(nf,2)\n",
    "v = np.random.rand(nf,2)\n",
    "mask = (1 - np.tri(nf)) * -1e10\n",
    "x = masked_attention(q, k, v, mask)\n",
    "print(x)\n",
    "\n",
    "# [[0.37646796 0.24378126]\n",
    "#  [0.48299578 0.28439644]\n",
    "#  [0.46590072 0.41837738]\n",
    "#  [0.52991302 0.51314059]\n",
    "#  [0.49214214 0.55574465]\n",
    "#  [0.39568092 0.59955323]\n",
    "#  [0.38462954 0.61108759]\n",
    "#  [0.37248739 0.5645996 ]\n",
    "#  [0.35915127 0.57331419]\n",
    "#  [0.41913397 0.51187079]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_projection(x, w, b):\n",
    "    projection = x @ w + b\n",
    "    return projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49964645 0.7764272  0.59947811]\n",
      " [1.0642018  1.42264665 0.86367775]\n",
      " [1.06047186 1.43087917 1.14610938]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "np.random.seed(4321)\n",
    "x = np.random.rand(3,2)\n",
    "w = np.random.rand(2,3)\n",
    "b = np.random.rand(3,1)\n",
    "lp = linear_projection(x, w, b)\n",
    "print(lp)\n",
    "\n",
    "# ->\n",
    "\n",
    "# [[0.49964645 0.7764272  0.59947811]\n",
    "#  [1.0642018  1.42264665 0.86367775]\n",
    "#  [1.06047186 1.43087917 1.14610938]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_head_attention(x, attn, number_of_heads):\n",
    "    w_1, b_1 = attn[\"c_attn\"][\"w\"], attn[\"c_attn\"][\"b\"]\n",
    "    w_2, b_2 = attn[\"c_proj\"][\"w\"], attn[\"c_proj\"][\"b\"]\n",
    "    mask = (1 - np.tri(x.shape[0], dtype=x.dtype)) * -1e10\n",
    "    lp = linear_projection(x, w_1, b_1)\n",
    "    # Seperate Q,K and V matrices\n",
    "    m = lp.shape[1]\n",
    "    if np.mod(m,3) == 0:\n",
    "        d = m/3\n",
    "        split = np.hsplit(lp,3) \n",
    "        Q = split[0]\n",
    "        K = split[1]\n",
    "        V = split[2]\n",
    "    Q_split = np.hsplit(Q,number_of_heads)\n",
    "    K_split = np.hsplit(K,number_of_heads)\n",
    "    V_split = np.hsplit(V,number_of_heads)  \n",
    "    # Perform masked attention over each head\n",
    "    for i in range(number_of_heads):\n",
    "        x_new = masked_attention(Q_split[i],K_split[i],V_split[i],mask)\n",
    "        if i == 0:\n",
    "            x = x_new\n",
    "        else:\n",
    "            x = np.concatenate([x,x_new], axis=1)\n",
    "    # Second linear projection with w_2 and b_2\n",
    "    x = linear_projection(x, w_2, b_2)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.4897257  2.74884012 2.6448295 ]\n",
      " [3.15425828 2.46024887 2.34563449]\n",
      " [3.22513764 2.50993895 2.38375606]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(4321)\n",
    "x = np.random.rand(3,4)\n",
    "w_1 = np.random.rand(4,12)\n",
    "b_1 = np.random.rand(3,1)\n",
    "w_2 = np.random.rand(4,3)\n",
    "b_2 = np.random.rand(3,1)\n",
    "attn = {\"c_attn\": {\"w\": w_1, \"b\": b_1}, \"c_proj\": {\"w\": w_2, \"b\": b_2}}\n",
    "x = multi_head_attention(x, attn, 2)\n",
    "print(x)\n",
    "\n",
    "# [[3.4897257  2.74884012 2.6448295 ]\n",
    "#  [3.15425828 2.46024887 2.34563449]\n",
    "#  [3.22513764 2.50993895 2.38375606]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:Couldn't match files for checkpoint models\\124M\\model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.00kb [00:00, ?b/s]                                                           \n",
      "Fetching encoder.json: 1.04Mb [00:01, 874kb/s]                                                      \n",
      "Fetching hparams.json: 1.00kb [00:00, ?b/s]                                                         \n",
      "Fetching model.ckpt.data-00000-of-00001: 498Mb [02:23, 3.46Mb/s]                                    \n",
      "Fetching model.ckpt.index: 6.00kb [00:00, 6.52Mb/s]                                                 \n",
      "Fetching model.ckpt.meta: 472kb [00:00, 601kb/s]                                                    \n",
      "Fetching vocab.bpe: 457kb [00:00, 643kb/s]                                                          \n",
      "Thinking...: 100%|██████████| 40/40 [00:06<00:00,  6.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe best food is the one that is good for you.\\n\\nThe best food is the one that is good for you.\\n\\nThe best food is the one that is good for'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(\"What is the best food there is?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
